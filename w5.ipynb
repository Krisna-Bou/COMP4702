{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/COMP4702-UQ/Pracs-notebook/blob/main/PracW5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "Sn5zSNyN6UCv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "\n",
        "# Mount google colab to drive to access to the dataset (uncomment if you use Google Colab + Drive)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7_HQqqP608G"
      },
      "source": [
        "# Q1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "GdrCuq6_6z9_"
      },
      "outputs": [],
      "source": [
        "# TODO: Load dataset\n",
        "# w3classif = ... # Specify full path if you use Google Colab + Drive\n",
        "\n",
        "data = pd.read_csv(\"./w3classif.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "GHGgsCKw7OQL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Create function for generating 10 train-test splits\n",
        "def create_train_test_data(data, test_size=0.3):\n",
        "    trains, tests = [], []\n",
        "\n",
        "    for i in range(10):\n",
        "        # Shuffle and split the dataset using a different random_state each time\n",
        "        train_data, test_data = train_test_split(data, test_size=test_size, random_state=i, shuffle=True)\n",
        "        trains.append(train_data)\n",
        "        tests.append(test_data)\n",
        "\n",
        "    return trains, tests\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFcjavtQ8Zp7"
      },
      "source": [
        "# Q2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "C-xKodm78eHS"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Assume `data` is already defined globally (e.g., loaded from w3classif.csv)\n",
        "def repeat_knn(trials=10, test_size=0.3):\n",
        "    train_losses, test_losses = [], []\n",
        "\n",
        "    # Use global data variable\n",
        "    trains, tests = create_train_test_data(data, test_size)\n",
        "\n",
        "    for i in range(trials):\n",
        "        train_df = trains[i]\n",
        "        test_df = tests[i]\n",
        "\n",
        "        # Split features and targets\n",
        "        X_train = train_df.iloc[:, :-1].values\n",
        "        y_train = train_df.iloc[:, -1].values\n",
        "        X_test = test_df.iloc[:, :-1].values\n",
        "        y_test = test_df.iloc[:, -1].values\n",
        "\n",
        "        # Initialize k-NN classifier (k=5 by default)\n",
        "        knn = KNeighborsClassifier(n_neighbors=5)\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on train and test sets\n",
        "        y_train_pred = knn.predict(X_train)\n",
        "        y_test_pred = knn.predict(X_test)\n",
        "\n",
        "        # Accuracy\n",
        "        train_acc = accuracy_score(y_train, y_train_pred)\n",
        "        test_acc = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "        # Loss (misclassification rate)\n",
        "        train_losses.append(1 - train_acc)\n",
        "        test_losses.append(1 - test_acc)\n",
        "\n",
        "    return train_losses, test_losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "NqW6b8EY-NMr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg Training Loss (Misclassification Rate): 0.0326\n",
            "Avg Test Loss (Misclassification Rate): 0.0450\n"
          ]
        }
      ],
      "source": [
        "# Print the average training and test losses for 10 trials using the function implemented above\n",
        "train_losses, test_losses = repeat_knn(trials=10, test_size=0.3)\n",
        "print(f'Avg Training Loss (Misclassification Rate): {np.array(train_losses).mean():.4f}')\n",
        "print(f'Avg Test Loss (Misclassification Rate): {np.array(test_losses).mean():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p4axUHW-mYY"
      },
      "source": [
        "# Q3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "et4o2flU-YdO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test size:  0.3\n",
            "Avg Training Loss (Misclassification Rate): 0.0326\n",
            "Avg Test Loss (Misclassification Rate): 0.0450\n",
            "__________________________________________________\n",
            "Test size:  0.5\n",
            "Avg Training Loss (Misclassification Rate): 0.0367\n",
            "Avg Test Loss (Misclassification Rate): 0.0440\n",
            "__________________________________________________\n",
            "Test size:  0.1\n",
            "Avg Training Loss (Misclassification Rate): 0.0301\n",
            "Avg Test Loss (Misclassification Rate): 0.0575\n",
            "__________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# TODO: Define all possible test set sizes\n",
        "test_sizes = [0.3, 0.5, 0.1]\n",
        "\n",
        "for ts in test_sizes:\n",
        "  # TODO: Repeat Q1 and Q2 and print the average loss for 10 trials for each test set size\n",
        "  print(\"Test size: \", ts)\n",
        "  train_losses, test_losses = repeat_knn(10, ts)\n",
        "  print(f'Avg Training Loss (Misclassification Rate): {np.array(train_losses).mean():.4f}')\n",
        "  print(f'Avg Test Loss (Misclassification Rate): {np.array(test_losses).mean():.4f}')  \n",
        "  print(\"__________________________________________________\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xClMuw8A_BWF"
      },
      "source": [
        "# Q4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "bj_HNZyV_KTE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test size:  0.3\n",
            "Avg Training Loss (Misclassification Rate): 0.0078\n",
            "Avg Test Loss (Misclassification Rate): 0.0119\n",
            "__________________________________________________\n",
            "Test size:  0.5\n",
            "Avg Training Loss (Misclassification Rate): 0.0106\n",
            "Avg Test Loss (Misclassification Rate): 0.0086\n",
            "__________________________________________________\n",
            "Test size:  0.1\n",
            "Avg Training Loss (Misclassification Rate): 0.0039\n",
            "Avg Test Loss (Misclassification Rate): 0.0297\n",
            "__________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# TODO: Define all possible test set sizes\n",
        "test_sizes = [0.3, 0.5, 0.1]\n",
        "\n",
        "for ts in test_sizes:\n",
        "  # TODO: Repeat Q1 and Q2 and print the average loss for 10 trials for each test set size\n",
        "  print(\"Test size: \", ts)\n",
        "  train_losses, test_losses = repeat_knn(10, ts)\n",
        "  print(f'Avg Training Loss (Misclassification Rate): {np.array(train_losses).std():.4f}')\n",
        "  print(f'Avg Test Loss (Misclassification Rate): {np.array(test_losses).std():.4f}')  \n",
        "  print(\"__________________________________________________\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrYcoSg__jdY"
      },
      "source": [
        "# Q5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "bNkpYItl_Oh5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Cross-Validation Error: 0.0426\n",
            "Standard Deviation of Error: 0.0251\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load and shuffle the dataset\n",
        "data = pd.read_csv(\"w3classif.csv\").sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "\n",
        "# Initialize the k-NN classifier (e.g., with k=5)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "num_folds = 10\n",
        "\n",
        "# Perform cross-validation and get accuracy scores\n",
        "accuracy_scores = cross_val_score(knn, X, y, cv=num_folds, scoring='accuracy')\n",
        "\n",
        "# Calculate error as (1 - accuracy)\n",
        "errors = 1 - accuracy_scores\n",
        "\n",
        "# Calculate mean and standard deviation of cross-validation error\n",
        "mean_error = np.mean(errors)\n",
        "std_error = np.std(errors)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Mean Cross-Validation Error: {mean_error:.4f}\")\n",
        "print(f\"Standard Deviation of Error: {std_error:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMT/u02ISpHSYqzzmw6N/b/",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
